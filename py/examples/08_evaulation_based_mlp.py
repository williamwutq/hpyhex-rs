"""
Example 8: NRSearch-Based MLP Training and Benchmarking

This example demonstrates training a Multi-Layer Perceptron (MLP) using data
generated by the NRSearch algorithm. The process involves:

1. Generating a large dataset of game states and move evaluations using NRSearch
2. Serializing the dataset to binary files for persistence
3. Loading and deserializing the data for training
4. Training an MLP to predict move quality scores
5. Benchmarking the trained MLP by playing complete games

The MLP learns to predict the NRSearch score for specific piece placements,
enabling it to make strategic decisions similar to the NRSearch heuristic.
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import numpy as np
import time
import pickle
import os
from typing import List, Tuple

from hpyhex import Hex, Piece, HexEngine, Game, PieceFactory


def nrsearch(engine: HexEngine, queue: List[Piece]) -> Tuple[int, Hex]:
    """
    A heuristic algorithm that selects the best piece and position based on
    the dense index, piece length, and score gain from elimination.

    This algorithm computes a comprehensive score for each piece and position by:
    1. Computing the dense index (local density around placement)
    2. Adding the piece length (reward for placing larger pieces)
    3. Simulating the move and adding elimination score (reward for clearing lines)

    This is considered the best algorithm in the nrminimax package.

    Parameters:
        engine (HexEngine): The game engine.
        queue (list[Piece]): The queue of pieces available for placement.

    Returns:
        placement (tuple[int, Hex]): A tuple containing the index of the best
                                     piece and the best position to place it.

    Raises:
        ValueError: If the queue is empty or no valid positions are found.
    """
    options = []
    seen_pieces = {}

    # Iterate through all pieces in the queue
    for piece_index, piece in enumerate(queue):
        key = int(piece)

        # Skip duplicate pieces (same state value)
        if key in seen_pieces:
            continue
        seen_pieces[key] = piece_index

        # Check all valid positions for this piece
        for coord in engine.check_positions(piece):
            # Compute base score: dense index + piece length
            score = engine.compute_dense_index(coord, piece) + len(piece)

            # Simulate the move to compute elimination benefit
            copy_engine = engine.__copy__()
            copy_engine.add_piece(coord, piece)
            elimination_score = len(copy_engine.eliminate()) / engine.radius
            score += elimination_score

            options.append((piece_index, coord, score))

    if not options:
        raise ValueError("No valid options found")

    # Return the piece and position with the highest score
    best_placement = max(options, key=lambda item: item[2])
    best_piece_option, best_position_option, best_score_result = best_placement

    return (best_piece_option, best_position_option)


def generate_nrsearch_samples(n_samples=50000, radius=5, queue_length=3, save_path='nrsearch_samples.pkl'):
    """
    Generate a large dataset of game states and move evaluations using NRSearch.

    For each sample, we record:
    - Current board state (serialized)
    - Piece being placed (serialized)
    - Position coordinates (i, j, k)
    - NRSearch score for this specific placement

    Parameters:
        n_samples: Target number of samples to generate
        radius: Board radius
        queue_length: Length of piece queue
        save_path: Path to save the serialized samples
    """
    print(f"Generating {n_samples} NRSearch-based samples...")
    print(f"Board radius: {radius}, Queue length: {queue_length}")

    samples = []
    games_played = 0

    while len(samples) < n_samples:
        games_played += 1
        game = Game(radius, queue_length)

        while not game.end and len(samples) < n_samples:
            # For each possible piece and position, compute NRSearch score
            for piece_idx, piece in enumerate(game.queue):
                positions = game.engine.check_positions(piece)
                for pos in positions:
                    # Compute the NRSearch score for this placement
                    dense = game.engine.compute_dense_index(pos, piece)
                    length = len(piece)

                    # Simulate placement to compute elimination
                    copy_engine = game.engine.__copy__()
                    copy_engine.add_piece(pos, piece)
                    elimination = len(copy_engine.eliminate()) / game.engine.radius
                    score = dense + length + elimination

                    # Serialize current state
                    board_bytes = game.engine.hpyhex_rs_serialize()
                    piece_bytes = piece.hpyhex_rs_serialize()

                    # Record sample
                    samples.append((board_bytes, piece_bytes, pos.i, pos.j, pos.k, score))

                    if len(samples) >= n_samples:
                        break
                if len(samples) >= n_samples:
                    break

            # Make a random move to progress the game (or use NRSearch)
            if not game.end:
                try:
                    best_piece_idx, best_pos = nrsearch(game.engine, game.queue)
                    game.add_piece(best_piece_idx, best_pos)
                except ValueError:
                    break  # No moves available

        if games_played % 10 == 0:
            print(f"  Generated {len(samples)} samples from {games_played} games...")

    print(f"Generated {len(samples)} samples from {games_played} games")

    # Save to binary file
    print(f"Saving samples to {save_path}...")
    with open(save_path, 'wb') as f:
        pickle.dump(samples, f)
    print(f"Samples saved. File size: {os.path.getsize(save_path)} bytes")

    return samples


class NRSearchDataset(Dataset):
    """Dataset for NRSearch-generated training samples."""

    def __init__(self, samples):
        """
        Initialize dataset from serialized samples.

        Args:
            samples: List of (board_bytes, piece_bytes, i, j, k, score) tuples
        """
        self.samples = samples

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        board_bytes, piece_bytes, i, j, k, score = self.samples[idx]

        # Deserialize
        board = HexEngine.hpyhex_rs_deserialize(board_bytes)
        piece = Piece.hpyhex_rs_deserialize(piece_bytes)

        # Convert to numpy arrays
        board_np = board.to_numpy_float32()
        piece_np = piece.to_numpy_float32()
        pos_np = np.array([i, j, k], dtype=np.float32)

        # Concatenate features: board + piece + position
        features = np.concatenate([board_np, piece_np, pos_np])

        return torch.FloatTensor(features), torch.FloatTensor([score])


class MovePredictorMLP(nn.Module):
    """MLP for predicting NRSearch move quality scores."""

    def __init__(self, input_size, hidden_sizes=[256, 256, 128, 64]):
        """
        Initialize the MLP.

        Args:
            input_size: Size of input features (board + piece + position)
            hidden_sizes: List of hidden layer sizes
        """
        super(MovePredictorMLP, self).__init__()

        layers = []
        prev_size = input_size

        # Build hidden layers
        for hidden_size in hidden_sizes:
            layers.append(nn.Linear(prev_size, hidden_size))
            layers.append(nn.ReLU())
            layers.append(nn.Dropout(0.1))
            prev_size = hidden_size

        # Output layer (single value: move quality score)
        layers.append(nn.Linear(prev_size, 1))

        self.network = nn.Sequential(*layers)

    def forward(self, x):
        return self.network(x)


def train_mlp(model, train_loader, val_loader, epochs=40, lr=0.0005, device='cpu'):
    """
    Train the MLP model.

    Args:
        model: The neural network model
        train_loader: Training data loader
        val_loader: Validation data loader
        epochs: Number of training epochs
        lr: Learning rate
        device: Device to train on
    """
    print("\n" + "=" * 60)
    print("Training MLP Model")
    print("=" * 60)

    model.to(device)
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=lr)

    for epoch in range(epochs):
        # Training phase
        model.train()
        train_loss = 0.0
        train_samples = 0

        for features, targets in train_loader:
            features, targets = features.to(device), targets.to(device)
            optimizer.zero_grad()
            outputs = model(features)
            loss = criterion(outputs, targets)
            loss.backward()
            optimizer.step()

            train_loss += loss.item() * features.size(0)
            train_samples += features.size(0)

        # Validation phase
        model.eval()
        val_loss = 0.0
        val_samples = 0

        with torch.no_grad():
            for features, targets in val_loader:
                features, targets = features.to(device), targets.to(device)
                outputs = model(features)
                loss = criterion(outputs, targets)

                val_loss += loss.item() * features.size(0)
                val_samples += features.size(0)

        # Print statistics
        avg_train_loss = train_loss / train_samples
        avg_val_loss = val_loss / val_samples

        print(f"Epoch {epoch + 1}/{epochs} - "
              f"Train Loss: {avg_train_loss:.4f}, "
              f"Val Loss: {avg_val_loss:.4f}")

    print("\nTraining completed!")


def load_samples(save_path='nrsearch_samples.pkl'):
    """Load serialized samples from file."""
    print(f"Loading samples from {save_path}...")
    with open(save_path, 'rb') as f:
        samples = pickle.load(f)
    print(f"Loaded {len(samples)} samples")
    return samples


def benchmark_mlp_vs_nrsearch(model, n_games=8, radius=5, queue_length=3, device='cpu'):
    """
    Benchmark the trained MLP against NRSearch by playing complete games.

    Args:
        model: Trained MLP model
        n_games: Number of games to play
        radius: Board radius
        queue_length: Queue length
        device: Device for model inference
    """
    print("\n" + "=" * 60)
    print(f"Benchmarking MLP vs NRSearch ({n_games} games)")
    print("=" * 60)

    model.to(device)
    model.eval()

    mlp_scores = []
    mlp_times = []
    nrsearch_scores = []
    nrsearch_times = []

    for game_num in range(n_games):
        print(f"\nGame {game_num + 1}/{n_games}")

        # Play with MLP
        print("  Playing with MLP...")
        start_time = time.time()
        game = Game(radius, queue_length)
        moves = 0
        while not game.end:
            positions = game.engine.check_positions(game.queue[0])
            if not positions:
                break

            best_score = -float('inf')
            best_pos = None

            # Evaluate each position
            for pos in positions:
                # Create features for this placement
                board_np = game.engine.to_numpy_float32()
                piece_np = game.queue[0].to_numpy_float32()
                pos_np = np.array([pos.i, pos.j, pos.k], dtype=np.float32)
                features = np.concatenate([board_np, piece_np, pos_np])
                features_tensor = torch.FloatTensor(features).unsqueeze(0).to(device)

                with torch.no_grad():
                    predicted_score = model(features_tensor).item()

                if predicted_score > best_score:
                    best_score = predicted_score
                    best_pos = pos

            if best_pos is None:
                break

            game.add_piece(0, best_pos)
            moves += 1

        mlp_time = time.time() - start_time
        mlp_scores.append(game.score)
        mlp_times.append(mlp_time)
        print(f"    MLP: Score {game.score}, Moves {moves}, Time {mlp_time:.2f}s")

        # Play with NRSearch
        print("  Playing with NRSearch...")
        start_time = time.time()
        game = Game(radius, queue_length)
        moves = 0
        while not game.end:
            try:
                best_piece_idx, best_pos = nrsearch(game.engine, game.queue)
                game.add_piece(best_piece_idx, best_pos)
                moves += 1
            except ValueError:
                break

        nrsearch_time = time.time() - start_time
        nrsearch_scores.append(game.score)
        nrsearch_times.append(nrsearch_time)
        print(f"    NRSearch: Score {game.score}, Moves {moves}, Time {nrsearch_time:.2f}s")

    # Summary
    print("\n" + "=" * 60)
    print("Benchmark Results")
    print("=" * 60)

    mlp_scores = np.array(mlp_scores)
    nrsearch_scores = np.array(nrsearch_scores)
    mlp_times = np.array(mlp_times)
    nrsearch_times = np.array(nrsearch_times)

    print("MLP Performance:")
    print(f"  Scores: {mlp_scores.mean():.1f} ± {mlp_scores.std():.1f} "
          f"(min: {mlp_scores.min():.0f}, max: {mlp_scores.max():.0f})")
    print(f"  Avg time per game: {mlp_times.mean():.2f}s")

    print("\nNRSearch Performance:")
    print(f"  Scores: {nrsearch_scores.mean():.1f} ± {nrsearch_scores.std():.1f} "
          f"(min: {nrsearch_scores.min():.0f}, max: {nrsearch_scores.max():.0f})")
    print(f"  Avg time per game: {nrsearch_times.mean():.2f}s")

    improvement = (nrsearch_scores.mean() - mlp_scores.mean()) / nrsearch_scores.mean() * 100
    print(f"\nNRSearch outperforms MLP by {improvement:.1f}%")


def main():
    """Run the NRSearch-based MLP example."""
    print("\n" + "=" * 60)
    print("HpyHex-RS NRSearch-Based MLP Example")
    print("=" * 60)
    print("Training an MLP using NRSearch-generated data\n")

    # Configuration
    RADIUS = 5
    QUEUE_LENGTH = 3
    N_SAMPLES = 50000  # Generate 50k samples
    TRAIN_SPLIT = 0.8
    BATCH_SIZE = 64
    EPOCHS = 15
    LEARNING_RATE = 0.001
    SAMPLE_FILE = 'nrsearch_samples.pkl'

    # Check if samples already exist
    if os.path.exists(SAMPLE_FILE):
        print(f"Found existing sample file: {SAMPLE_FILE}")
        samples = load_samples(SAMPLE_FILE)
    else:
        # Generate samples
        samples = generate_nrsearch_samples(
            n_samples=N_SAMPLES,
            radius=RADIUS,
            queue_length=QUEUE_LENGTH,
            save_path=SAMPLE_FILE
        )

    # Split into train/val
    np.random.shuffle(samples)
    split_idx = int(len(samples) * TRAIN_SPLIT)
    train_samples = samples[:split_idx]
    val_samples = samples[split_idx:]

    print(f"\nDataset split: {len(train_samples)} train, {len(val_samples)} validation")

    # Create datasets and loaders
    train_dataset = NRSearchDataset(train_samples)
    val_dataset = NRSearchDataset(val_samples)

    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)

    # Calculate input size
    sample_features, _ = train_dataset[0]
    input_size = sample_features.shape[0]

    print(f"\nModel configuration:")
    print(f"  Input size: {input_size}")
    print(f"  Hidden layers: [256, 128, 64]")
    print(f"  Output size: 1 (NRSearch score)")

    # Create model
    model = MovePredictorMLP(input_size=input_size, hidden_sizes=[256, 128, 64])

    # Count parameters
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"\nTotal parameters: {total_params:,}")
    print(f"Trainable parameters: {trainable_params:,}")

    # Train the model
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"\nUsing device: {device}")
    train_mlp(model, train_loader, val_loader, epochs=EPOCHS, lr=LEARNING_RATE, device=device)

    # Save the trained model
    torch.save(model.state_dict(), 'nrsearch_mlp.pth')
    print(f"\nModel saved to nrsearch_mlp.pth")

    # Benchmark
    benchmark_mlp_vs_nrsearch(model, n_games=8, radius=RADIUS, queue_length=QUEUE_LENGTH, device=device)

    print("\n" + "=" * 60)
    print("NRSearch-based MLP example completed!")
    print("=" * 60)
    print("\nKey takeaways:")
    print("- NRSearch generates high-quality training data for ML models")
    print("- MLP can learn to approximate NRSearch decision-making")
    print("- Binary serialization enables efficient data persistence")
    print("- While MLP may not match NRSearch performance, it offers")
    print("  faster inference for real-time applications")
    print("- This approach demonstrates ML-based game AI using expert data")


if __name__ == "__main__":
    main()